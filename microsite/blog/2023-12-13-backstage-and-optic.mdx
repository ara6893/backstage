# Validating OpenAPI schemas with test traffic using Optic

Hey all, today I'm going to be talking about Backstage's use of [Optic's](https://github.com/opticdev/optic) `capture` command, why I think you should use it too, and why it's really cool. Most of you reading this probably don't know me, so let me introduce myself. I'm Aramis, maintainer of Backstage's OpenAPI tooling project area, I've been working for the past year on improving the schema-first developer experience inside of Backstage.

## What were we trying to solve?

Backstage is a fullstack Typescript application. Plugins are written using React in the frontend and express.js in the backend. All clients in the frontend and all validation schemas in the backend are handwritten. While there a few cases where the schema is so complex that it can't be described by a simple schema, for most cases. this duplication of work adds more toil to the Backstage plugin developer's workflow. Enter schema-first development...

## What is schema-first development?

Schema-first development is using a schema, ie GraphQL, OpenAPI, gRPC, etc, to drive server and front end client implementation. It requires developers to be comfortable with the schema and expects developers to start any changes at the schema instead of at the router or client layer.

## How does that fit into the OpenAPI tooling project area?

The OpenAPI tooling project area's goal is to enable developers to leverage schema-first development best practices in their Backstage plugins. This includes typed express routers based on an OpenAPI spec, autogenerated clients from a spec, and validation between OpenAPI spec and runtime traffic. You can find more information and a roadmap in [this meta issue](https://github.com/backstage/backstage/issues/17482) and for more history on how this became a project area, see the discussion on [the original issue](https://github.com/backstage/backstage/issues/2566).

## What other tools exist in the project area?

As I mentioned above, thus far, we've delivered

1. an autogenerated express router stub with typings ([#15667](https://github.com/backstage/backstage/pull/15667))
2. an autogenerated client with Backstage-specific tie-ins ([#17470](https://github.com/backstage/backstage/pull/17470))
3. runtime validation with `express-openapi-validator` ([#17875](https://github.com/backstage/backstage/pull/17875))

and a few others. Again, check out [the meta issue](https://github.com/backstage/backstage/issues/17482) for the full rundown.

The above tools reduce the load on developers to maintain multiple sources of truth. Before these tools, developers maintained multiple sources of truth across Zod schemas, frontend clients, and router parameter and return values. Having this many disparate source of truth made it easy to fracture validation and typings. By focusing on the schema as the source of truth, the fracturing disappears.

## How did you end up at test validation?

All of the above tools provide outputs based on the schema. They do not perform validation of the contents of the schema based on known expected input/output pairings. They don't have strong feedback loops beyond type, build or runtime errors, especially as all of those require a generation step to run before they can give feedback. So, we wanted to find a way to validate based on known expected input/output pairing.

Lo and behold, we had unit tests for routers that provided exactly that, including status code checks and error response validation. Not just that, but by using unit tests, you can use your existing test framework to validate that your test is correct before validating the whole router test suite against the spec, ie using `jest` before using Optic's `capture`.

Truthfully, I didn't know this was an option until I stumbled across Optic's `capture` command.

The idea behind it is genius and yet remarkably simple -- validating your OpenAPI schema against the unit tests you've written by using a reverse proxy for network traffic. The reverse proxy captures the traffic and proxies it to your backend, it also keeps track of that traffic and reports on any mismatches between the schema and the traffic after execution.

In our case, we had to override some internal properties of the router so that `supertest` calls the correct reverse proxy endpoint.

```ts
return {
  ...server,
  address: () => new URL(process.env.OPTIC_PROXY!),
} as any;
```

This _slight_ hack ensures that `supertest` calls the `OPTIC_PROXY` endpoint instead of the target express router's address.

Getting to this point took a fair amount of trial and error, and the Optic team was very helpful and responsive on Discord and happy to jump on a call for more support. Once we got the integration set up fully, it was smooth sailing.

## Effects of test validation

One of the cool things about working in open source is that I can directly show you what the effects of this integration have been on the project. So far, we've just integrated with 2 plugins, but expect to integrate with more soon as we start rolling out the tooling to more and more folks.

You can find the PR that added this command [here](https://github.com/backstage/backstage/pull/19955). A few of the issues that this command helped uncover are

- ```diff
  +        '201':
  +          description: 201 response
  +          content:
  +            application/json:
  +              schema:
  +                type: object
  +                properties:
  +                  location:
  +                    type: object
  +                    properties:
  +                      id:
  +                        type: string
  +                      type:
  +                        type: string
  +                      target:
  +                        type: string
  +                    required:
  +                      - id
  +                      - type
  +                      - target
  +                  entities:
  +                    type: array
  +                    items: {}
  +                required:
  +                  - location
  +                  - entities
  ```

- ```diff
  /refresh:
      post:
      operationId: RefreshEntity
      description: Refresh the entity related to entityRef.
      responses:
          '200':
          description: Refreshed
  +       '400':
  +         $ref: '#/components/responses/ErrorResponse'
  +       default:
  +         $ref: '#/components/responses/ErrorResponse'
  ```
- ```diff
      JsonObject:
      type: object
      properties: {}
      description: A type representing all allowed JSON object values.
  +     additionalProperties: true
  ```

This also means that test cases can no longer have correctly typed but incorrectly completed input data. Something like,

```ts
const entity: Entity = {} as any;

const response = await request(app)
  .post("/entities/by-refs")
  .set("Content-Type", "application/json")
  .send('{"entityRefs":["a"],"fields":["b"]}');
expect(response).toEqual(entity);
```

now causes validation issues and can't just be used for Typescript compiler satisfaction. I very much think that this is a positive thing and enforces testing best practices in a way that is easy to see the effect of -- bad data in, bad schema out.

And saving the best for last, this command can (and does) run as part of our CI as a validation step. By having it sit at the CI level, we ensure that users are correctly updating tests not just to pass but to have the expected input/output values.

## Generating a spec from traffic

One more thing that I want to talk about briefly is the `capture` command's `--update interactive` option. This allows the command to construct a schema from the traffic that it has captured. You can either use this to bootstrap a complete schema or update a piece of an existing schema. Our use of this in the Backstage project is experimental, but I've been impressed by the results and I think others may be as well.

One of our goals with the OpenAPI tooling project is to create a bootstrapping experience for existing plugins to easily lift-and-shift them onto OpenAPI tooling. I expect this command to be an integral part of that experience as it would be the core spec generation functionality.

### Quick example using the Azure DevOps plugin

Andre Wanlin asked me a few weeks ago to help him onboard the Azure DevOps plugin to the new OpenAPI tooling, with his main interest being the creation of an OpenAPI spec. [Here's](https://github.com/sennyeya/backstage/blob/dev-ops-openapi-spec/plugins/azure-devops-backend/src/schema/openapi.yaml) the spec that I ended up creating. If you were to clone this branch locally, you would find that there are a bunch of type errors. For example,

```ts
router.get("/projects", async (_req, res) => {
  // no overload matches this call
  const projects = await azureDevOpsApi.getProjects();
  res.status(200).json(projects);
});
```

and you'd see that there is no matching path for this endpoint in the spec or in the tests.

Or,

```ts
router.get("/repo-builds/:projectName/:repoName", async (req, res) => {
  const { projectName, repoName } = req.params;

  const top = req.query.top ? Number(req.query.top) : DEFAULT_TOP; // Property 'top' does not exist on type

  const gitRepository = await azureDevOpsApi.getRepoBuilds(
    projectName,
    repoName,
    top
  );

  res.status(200).json(gitRepository);
});
```

which, if you look at the spec,

```yaml
/repo-builds/{projectName}/{repoName}:
  get:
    parameters:
      - in: path
        name: projectName
        required: true
        schema:
          type: string
      - in: path
        name: repoName
        required: true
        schema:
          type: string
    responses:
      "200":
        description: 200 response
        content:
          application/json; charset=utf-8:
            schema:
              $ref: "#/components/schemas/GetBuildsProjectname200ResponseBody"
```

you'll see that there are no query parameters, and the tests don't include it,

```ts
describe('GET /repo-builds/:projectName/:repoName', () => {
    it('fetches a list of repo builds', async () => {
      ...
      const response = await request(app)
        .get('/repo-builds/myProject/myRepo')
        .query({ top: '50' });

      expect(azureDevOpsApi.getRepoBuilds).toHaveBeenCalledWith(
        'myProject',
        'myRepo',
        50,
      );
      expect(response.status).toEqual(200);
      expect(response.body).toEqual(repoBuilds);
    });
  });
```

By tying validation _and_ spec generation to unit tests, we expect unit test quality to increase, like adding the query param to the test above, as well as improving spec quality. If we can get the tooling right, it becomes a nice virtuous cycle of unit test improvements matched with spec improvements and the Backstage ecosystem wins.

## Closing remarks

I've been extremely pleased with the test validation provided by Optic and I look forward to adopting other Optic tools in the future, like their linting or breaking changes validation.
